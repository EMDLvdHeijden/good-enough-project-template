---
title: "Bayesian_latent_class_analysis_HiP_MGR_v3"
author: "Elise_van_der_Heijden"
date: "10/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir="/Users/emdlvanderheijden/Documents/Work/Postdoc_VI_UU/Research/Projects/Bayesian_work/Re-Analysis_Ch3_Bayesian")
```

```{r Get ready for the analysis}
# Bayesian latent class model: Hui-Walter & Bayesian Logistic regression
# The underlying assumptions for a traditional Hui-Walter latent class model are the following:
# 1. The assays you are testing are conditionally independent: if test 1 is positive, this does not influence the likely outcome for test 2).
# 2. You test these assays in at least two populations that have a different prevalence.
# 3. The assays have the same test performance in both populations. (Check Bermingham et al. 2015 for a way to do H&W if this is not true)

# IDEA: First do traditional H&W assuming all 3 are true. Then repeat H&W using Bermingham et al. 21015 method, as we know from van der Heijden et al. 2020 that the assays perform differently in the two parks. Then we compare the outcomes.

getwd()
library(rjags)
library(ggplot2)
library(coda)
```

```{r Load the data}
# Load database HiPMGR
btb <- read.delim("Database HiPMGR.txt")
View(btb)
str(btb)
```

```{r Format the dataframe}
# Make a table of the various test result combinations stratified for the two populations
pop <- t(matrix(as.vector(table(btb$TBELISA_Result, btb$TST_Result, btb$Park_ID)),4,2))
View(pop)

# If you want to make this table without stratifying on population
# pop.all <- t(matrix(as.vector(table(btb$TST_Result, btb$TBELISA_Result)),4))

# Give the table column- and rownames and have a look at the data
colnames(pop) <- c("-/-", "-/+", "+/-", "+/+") # test 1 = TST; test 2 = TB ELISA
rownames(pop) <- c("HiP", "MGR")
pop

# Side note:
# If you want to order the dataframe like in some other publications, change it to:
# pop2 <- pop[,c(4,3,2,1)]
# You will then have to change the order of the definitions in the model too!!!!
# They are now in 4,2,3,1 as we have the data from -/- to +/+ like in the Bronsvoort et al. 2019 publication.

np <- nrow(pop)
# Create vector of population counts
n <- apply(pop,1,sum)
```

```{r Run the first model}
# Define the model
model1 <- "model{
  for (i in 1:2) { 
    p[i] ~ dbeta(1,1) 
    pop[i, 1:4] ~ dmulti(par[i,1:4], n[i]) 
    par[i, 4] <- p[i]*Se1*Se2 + (1-p[i])*(1-Sp1)*(1-Sp2) 
    par[i, 2] <- p[i]*Se1*(1-Se2) + (1-p[i])*(1-Sp1)*Sp2 
    par[i, 3] <- p[i]*(1-Se1)*Se2 + (1-p[i])*Sp1*(1-Sp2) 
    par[i, 1] <- p[i]*(1-Se1)*(1-Se2) + (1-p[i])*Sp1*Sp2
    } 
  ## priors
  Se1 ~ dbeta(1, 1)
  Sp1 ~ dbeta(1, 1)
  Se2 ~ dbeta(1, 1)
  Sp2 ~ dbeta(1, 1)
  
  # these priors are uninformative
  # try this model again with informative priors based on previous research of these tests in buffaloes
  
}"

# Compile the model
model1_jags <- jags.model(textConnection(model1),inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018),
                          data=list(pop=pop, n=n))
        # in Bronsvoort et al. own INITS defined (based on??) and also n.chains=3, n.adapt=50000)
        # in datacamp course usually inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018) which is what was used here.
        # should find out how to define our own inits - this seems key for the outcome!
                          

# Simulate the model
model1_sim <- coda.samples(model=model1_jags, variable.names=c("p", "Se1", "Se2", "Sp1", "Sp2"),
                            n.iter=10000)
        # in Bronsvoort et al. n.iter=250000, n.thin=100
        # the higher the number of iterarions, the more stable and reliable the outcome
        # used 10000 here for now for speed of estimation, should probably be higher!

```

```{r Plot the results of model1}
# Plot the posterior
plot(model1_sim)

# Summarize the data
summary(model1_sim)

# Store the MC chain
model1_chains <- data.frame(model1_sim[[1]], iter = 1:10000)

# Make plots of the different parameters

# Se1 = Se of the TST
ggplot(data=model1_chains, aes(x=Se1)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$Se1), color="red")

# Se2 = Se of the TB ELISA
ggplot(data=model1_chains, aes(x=Se2)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$Se2), color="red")

# Sp1 = Sp of the TST
ggplot(data=model1_chains, aes(x=Sp1)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$Sp1), color="red")

# Sp2 = SP of the TB ELISA
ggplot(data=model1_chains, aes(x=Sp2)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$Sp2), color="red")

# p1 = prevalence in HiP
ggplot(data=model1_chains, aes(x=p.1.)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$p.1.), color="red")

# p2 = prevalence in MGR
ggplot(data=model1_chains, aes(x=p.2.)) +
  geom_density() + geom_vline(xintercept=mean(model1_chains$p.2.), color="red")

# Convergence checks
 # gelman.diag(model1_sim) #need at least 2 chains for this
 # gelman.plot(model1_sim) #need at least 2 chains for this
 densplot(model1_sim)
 traceplot(model1_sim)

```

```{r Re-run of the analysis with informative priors - model 2}

# Use informative priors according to known previous estimates for the Se and Sp of TST and TB ELISA
# beta(1,1) * beta(s1,n1-s1) = beta(s1+1,n1-s1+1)
# in other words: from cross-tabs for Se -> beta(a+1,b+1) and for Sp <- beta(d+1,c+1)
# TST Se = 76.5% and Sp = 99.5% (Michel et al. 2011 and unpublished data)
Se1 <- hist(rbeta(10000, 138, 43))
Sp1 <- hist(rbeta(10000, 766, 5))
# TB ELISA Se = 37.5% and Sp = 100% (van der Heijden et al. 2016 and unpublished data)
Se2 <- hist(rbeta(10000, 4, 6))
Sp2 <- hist(rbeta(10000, 15, 1))

# Define the model
model2 <- "model{
  for (i in 1:2) { 
p[i] ~ dbeta(1,1) 
pop[i, 1:4] ~ dmulti(par[i,1:4], n[i]) 
par[i, 4] <- p[i]*Se1*Se2 + (1-p[i])*(1-Sp1)*(1-Sp2) 
par[i, 2] <- p[i]*Se1*(1-Se2) + (1-p[i])*(1-Sp1)*Sp2 
par[i, 3] <- p[i]*(1-Se1)*Se2 + (1-p[i])*Sp1*(1-Sp2) 
par[i, 1] <- p[i]*(1-Se1)*(1-Se2) + (1-p[i])*Sp1*Sp2
} 
## priors
Se1 ~ dbeta(138, 43)
Sp1 ~ dbeta(766, 5)
Se2 ~ dbeta(4, 6)
Sp2 ~ dbeta(15, 1)

}"

# Compile the model
model2_jags <- jags.model(textConnection(model2),inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018),
                          data=list(pop=pop, n=n))
# in Bronsvoort et al. own INITS defined (based on??) and also n.chains=3, n.adapt=50000)
# in datacamp course usually inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018) which is what was used here.
# should find out how to define our own inits - this seems key for the outcome!


# Simulate the model
model2_sim <- coda.samples(model=model2_jags, variable.names=c("p", "Se1", "Se2", "Sp1", "Sp2"),
                           n.iter=10000)
# in Bronsvoort et al. n.iter=250000, n.thin=100
# the higher the number of iterarions, the more stable and reliable the outcome
# used 10000 here for now for speed of estimation, should probably be higher!

```

```{r Plot the results of model2}
# Plot the posterior
plot(model2_sim)

# Summarize the data
summary(model2_sim)

# Store the MC chain
model2_chains <- data.frame(model2_sim[[1]], iter = 1:10000)

# Make plots of the different parameters
# Se1 = Se of the TST
ggplot(data=model2_chains, aes(x=Se1)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$Se1), color="red")

# Se2 = Se of the TB ELISA
ggplot(data=model2_chains, aes(x=Se2)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$Se2), color="red")

# Sp1 = Sp of the TST
ggplot(data=model2_chains, aes(x=Sp1)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$Sp1), color="red")

# Sp2 = SP of the TB ELISA
ggplot(data=model2_chains, aes(x=Sp2)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$Sp2), color="red")

# p1 = prevalence in HiP
ggplot(data=model2_chains, aes(x=p.1.)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$p.1.), color="red")

# p2 = prevalence in MGR
ggplot(data=model2_chains, aes(x=p.2.)) +
  geom_density() + geom_vline(xintercept=mean(model2_chains$p.2.), color="red")

# Convergence checks
 gelman.diag(model2_sim)
 gelman.plot(model2_sim)
 densityplot(model2_sim)
 traceplot(model2_sim)

```

```{r What if we stratify also on area within the park?}

# Reasoning is that in HiP in these three years, 3 separate areas were targeted and the prevalence is assumed different between these areas.
# Whereas in madikwe we targeted 6 areas and these were separated into 6 herds, all of the same rather small park though.
# First change the Herd_ID columns, because currently for HiP there are herds from different years with the same Herd_ID
btb2 <- btb
btb2$Herd_ID2 <- NA

btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_site == "Masinda", "HiP.A", Herd_ID2))

btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_site == "Corridor", "HiP.B", Herd_ID2))

btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_site == "Nselweni","HiP.C", Herd_ID2))

btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "1", "MGR.1", Herd_ID2))
btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "2", "MGR.2", Herd_ID2))
btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "3", "MGR.3", Herd_ID2))
btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "4", "MGR.4", Herd_ID2))
btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "5", "MGR.5", Herd_ID2))
btb2 <- transform(btb2, Herd_ID2 = ifelse(Study_Year == 2016 & Herd_ID == "6", "MGR.6", Herd_ID2))

# Make a table of the various test result combinations stratified for the 14 herds
pop2 <- t(matrix(as.vector(table(btb2$TBELISA_Result, btb2$TST_Result, btb2$Herd_ID2)),4,9))
View(pop2)

# Add colnames and rownames
# Give the table column- and rownames and have a look at the data
colnames(pop2) <- c("-/-", "-/+", "+/-", "+/+") # test 1 = TST; test 2 = TB ELISA
rownames(pop2) <- unique(btb2$Herd_ID2)
pop2

# Check whether the totals of test results still add up to the same as before
apply(pop2,2,sum) == apply(pop,2,sum) # all true so correct
apply(pop2,1,sum) # If you add up all the data per park HiP = 766 and MGR = 231 which is correct

# Create vector of population counts
np2 <- nrow(pop2)
n2 <- apply(pop2,1,sum)

```

```{R Run model 3}
# Define the model
model3 <- "model{
  for (i in 1:9) { 
    p[i] ~ dbeta(1,1) 
    pop[i, 1:4] ~ dmulti(par[i,1:4], n[i]) 
    par[i, 4] <- p[i]*Se1*Se2 + (1-p[i])*(1-Sp1)*(1-Sp2) 
    par[i, 2] <- p[i]*Se1*(1-Se2) + (1-p[i])*(1-Sp1)*Sp2 
    par[i, 3] <- p[i]*(1-Se1)*Se2 + (1-p[i])*Sp1*(1-Sp2) 
    par[i, 1] <- p[i]*(1-Se1)*(1-Se2) + (1-p[i])*Sp1*Sp2
    } 
  ## priors
  Se1 ~ dbeta(1, 1)
  Sp1 ~ dbeta(1, 1)
  Se2 ~ dbeta(1, 1)
  Sp2 ~ dbeta(1, 1)
  
  # these priors are uninformative
  # try this model again with informative priors based on previous research of these tests in buffaloes
  
}"

# Compile the model
model3_jags <- jags.model(textConnection(model3),inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018),
                          data=list(pop=pop2, n=n2))
        # in Bronsvoort et al. own INITS defined (based on??) and also n.chains=3, n.adapt=50000)
        # in datacamp course usually inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018) which is what was used here.
        # should find out how to define our own inits - this seems key for the outcome!
                          

# Simulate the model
model3_sim <- coda.samples(model=model3_jags, variable.names=c("p", "Se1", "Se2", "Sp1", "Sp2"),
                            n.iter=10000)
        # in Bronsvoort et al. n.iter=250000, n.thin=100
        # the higher the number of iterarions, the more stable and reliable the outcome, but probably depends on volume of data too?
        # used 10000 here for now for speed of estimation, should probably be higher!

```
```{r Plot the results of model3}
# Plot the posterior
plot(model3_sim)

# Summarize the data
summary(model3_sim)

# Store the MC chain
model3_chains <- data.frame(model3_sim[[1]], iter = 1:10000)

# Make plots of the different parameters

# Se1 = Se of the TST
ggplot(data=model3_chains, aes(x=Se1)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$Se1), color="red")

# Se2 = Se of the TB ELISA
ggplot(data=model3_chains, aes(x=Se2)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$Se2), color="red")

# Sp1 = Sp of the TST
ggplot(data=model3_chains, aes(x=Sp1)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$Sp1), color="red")

# Sp2 = SP of the TB ELISA
ggplot(data=model3_chains, aes(x=Sp2)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$Sp2), color="red")

# p1 = prevalence in HiP.A
ggplot(data=model3_chains, aes(x=p.1.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.1.), color="red")

# p2 = prevalence in HiP.B
ggplot(data=model3_chains, aes(x=p.2.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.2.), color="red")

# p3 = prevalence in HiP.C
ggplot(data=model3_chains, aes(x=p.3.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.3.), color="red")

# p4 = prevalence in MGR.1
ggplot(data=model3_chains, aes(x=p.4.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.4.), color="red")

# p5 = prevalence in MGR.2
ggplot(data=model3_chains, aes(x=p.5.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.5.), color="red")

# p6 = prevalence in MGR.3
ggplot(data=model3_chains, aes(x=p.6.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.6.), color="red")

# p7 = prevalence in MGR.4
ggplot(data=model3_chains, aes(x=p.7.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.7.), color="red")

# p8 = prevalence in MGR.5
ggplot(data=model3_chains, aes(x=p.8.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.8.), color="red")

# p9 = prevalence in MGR.6
ggplot(data=model3_chains, aes(x=p.9.)) +
  geom_density() + geom_vline(xintercept=mean(model3_chains$p.9.), color="red")


```

```{r Re-run this using priors - model4}

# Use informative priors according to known previous estimates for the Se and Sp of TST and TB ELISA
# beta(1,1) * beta(s1,n1-s1) = beta(s1+1,n1-s1+1)
# in other words: from cross-tabs for Se -> beta(a+1,b+1) and for Sp <- beta(d+1,c+1)
# TST Se = 76.5% and Sp = 99.5% (Michel et al. 2011 and unpublished data)
Se1 <- hist(rbeta(10000, 138, 43))
Sp1 <- hist(rbeta(10000, 766, 5))
# TB ELISA Se = 37.5% and Sp = 100% (van der Heijden et al. 2016 and unpublished data)
Se2 <- hist(rbeta(10000, 4, 6))
Sp2 <- hist(rbeta(10000, 15, 1))

# Define the model
model4 <- "model{
  for (i in 1:9) { 
    p[i] ~ dbeta(1,1) 
    pop[i, 1:4] ~ dmulti(par[i,1:4], n[i]) 
    par[i, 4] <- p[i]*Se1*Se2 + (1-p[i])*(1-Sp1)*(1-Sp2) 
    par[i, 2] <- p[i]*Se1*(1-Se2) + (1-p[i])*(1-Sp1)*Sp2 
    par[i, 3] <- p[i]*(1-Se1)*Se2 + (1-p[i])*Sp1*(1-Sp2) 
    par[i, 1] <- p[i]*(1-Se1)*(1-Se2) + (1-p[i])*Sp1*Sp2
    } 
  ## priors
  Se1 ~ dbeta(138, 43)
  Sp1 ~ dbeta(766, 5)
  Se2 ~ dbeta(4, 6)
  Sp2 ~ dbeta(15, 1)
  
}"

# Compile the model
model4_jags <- jags.model(textConnection(model4),inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018),
                          data=list(pop=pop2, n=n2))
        # in Bronsvoort et al. own INITS defined (based on??) and also n.chains=3, n.adapt=50000)
        # in datacamp course usually inits=list(.RNG.name = "base::Wichmann-Hill", .RNG.seed = 2018) which is what was used here.
        # should find out how to define our own inits - this seems key for the outcome!
                          

# Simulate the model
model4_sim <- coda.samples(model=model4_jags, variable.names=c("p", "Se1", "Se2", "Sp1", "Sp2"),
                            n.iter=10000)
        # in Bronsvoort et al. n.iter=250000, n.thin=100
        # the higher the number of iterarions, the more stable and reliable the outcome, but probably depends on volume of data too?
        # used 10000 here for now for speed of estimation, should probably be higher!


```

```{r Plot the results of model4}
# Plot the posterior
plot(model4_sim)

# Summarize the data
summary(model4_sim)

# Store the MC chain
model4_chains <- data.frame(model4_sim[[1]], iter = 1:10000)

# Make plots of the different parameters

# Se1 = Se of the TST
ggplot(data=model4_chains, aes(x=Se1)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$Se1), color="red")

# Se2 = Se of the TB ELISA
ggplot(data=model4_chains, aes(x=Se2)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$Se2), color="red")

# Sp1 = Sp of the TST
ggplot(data=model4_chains, aes(x=Sp1)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$Sp1), color="red")

# Sp2 = SP of the TB ELISA
ggplot(data=model4_chains, aes(x=Sp2)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$Sp2), color="red")

# p1 = prevalence in HiP.A
ggplot(data=model4_chains, aes(x=p.1.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.1.), color="red")

# p2 = prevalence in HiP.B
ggplot(data=model4_chains, aes(x=p.2.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.2.), color="red")

# p3 = prevalence in HiP.C
ggplot(data=model4_chains, aes(x=p.3.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.3.), color="red")

# p4 = prevalence in MGR.1
ggplot(data=model4_chains, aes(x=p.4.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.4.), color="red")

# p5 = prevalence in MGR.2
ggplot(data=model4_chains, aes(x=p.5.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.5.), color="red")

# p6 = prevalence in MGR.3
ggplot(data=model4_chains, aes(x=p.6.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.6.), color="red")

# p7 = prevalence in MGR.4
ggplot(data=model4_chains, aes(x=p.7.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.7.), color="red")

# p8 = prevalence in MGR.5
ggplot(data=model4_chains, aes(x=p.8.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.8.), color="red")

# p9 = prevalence in MGR.6
ggplot(data=model4_chains, aes(x=p.9.)) +
  geom_density() + geom_vline(xintercept=mean(model4_chains$p.9.), color="red")


```

```{r What if we define our own inits?}

# For this we use the model with informative priors according to known previous estimates as above. And data stratified on Park_ID
Se1 <- hist(rbeta(10000, 138, 43))
Sp1 <- hist(rbeta(10000, 766, 5))
Se2 <- hist(rbeta(10000, 4, 6))
Sp2 <- hist(rbeta(10000, 15, 1))

# Define the model
model5 <- "model{
  for (i in 1:2) { 
p[i] ~ dbeta(1,1) 
pop[i, 1:4] ~ dmulti(par[i,1:4], n[i]) 
par[i, 4] <- p[i]*Se1*Se2 + (1-p[i])*(1-Sp1)*(1-Sp2) 
par[i, 2] <- p[i]*Se1*(1-Se2) + (1-p[i])*(1-Sp1)*Sp2 
par[i, 3] <- p[i]*(1-Se1)*Se2 + (1-p[i])*Sp1*(1-Sp2) 
par[i, 1] <- p[i]*(1-Se1)*(1-Se2) + (1-p[i])*Sp1*Sp2
} 
## priors
Se1 ~ dbeta(138, 43)
Sp1 ~ dbeta(766, 5)
Se2 ~ dbeta(4, 6)
Sp2 ~ dbeta(15, 1)

}"

# Define the Inits
modelInits <- list(
  list(Se1=0.6, Sp1=0.99, Se2=0.2, Sp2=0.92, p=runif(length(n), 0.1, 0.35)),
  list(Se1=0.5, Sp1=0.97, Se2=0.1, Sp2=0.90, p=runif(length(n), 0.1, 0.35)),
  list(Se1=0.7, Sp1=0.94, Se2=0.3, Sp2=0.94, p=runif(length(n), 0.1, 0.35)))

# Compile the model
model5_jags <- jags.model(textConnection(model5),inits=modelInits, n.chains=3, n.adapt = 10000,
                          data=list(pop=pop, n=n))

# Simulate the model
model5_sim <- coda.samples(model=model5_jags, variable.names=c("p", "Se1", "Se2", "Sp1", "Sp2"),
                           n.iter=100000, n.thin=50)

```

```{r So let's look at this data - is it different?}

# Plot the posterior
plot(model5_sim)

# Summarize the data
summary(model5_sim)

# Store the MC chain
model5_chains <- data.frame(model5_sim[[1]], iter = 1:10000)

# Make plots of the different parameters
# Se1 = Se of the TST
ggplot(data=model5_chains, aes(x=Se1)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$Se1), color="red")

# Se2 = Se of the TB ELISA
ggplot(data=model5_chains, aes(x=Se2)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$Se2), color="red")

# Sp1 = Sp of the TST
ggplot(data=model5_chains, aes(x=Sp1)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$Sp1), color="red")

# Sp2 = SP of the TB ELISA
ggplot(data=model5_chains, aes(x=Sp2)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$Sp2), color="red")

# p1 = prevalence in HiP
ggplot(data=model5_chains, aes(x=p.1.)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$p.1.), color="red")

# p2 = prevalence in MGR
ggplot(data=model5_chains, aes(x=p.2.)) +
  geom_density() + geom_vline(xintercept=mean(model5_chains$p.2.), color="red")

# We see that this didn't have much influence on the outcome at all. It is possibly more robust because we use more chains and pick our own inits.
# But may have to choose more appropriate inits? Not sure how to accurately define these. Doesn't seem to have the same influence as priors.
# Probably because inits are just initial values from which the MCMC chains start, but they produce 100000 iterations of other values.


```




```{r}

# Another way of doing the analysis is like in Cheung et al. 2021 (OIE)
# For this analysis we need some extra packages. This is hard to do on a mac!
library(epiR) #for epi.betabuster
library(R2OpenBUGS) #for driving OpenBUGS from R
library(mcmcplots) #for plotting

# Specify the model:
model=paste0("model{

    #Multinomial Model for the Data
    x1[1:2,1:2] ~ dmulti(p1[1:2,1:2], n1)
    x2[1:2,1:2] ~ dmulti(p2[1:2,1:2], n2)

    #Observed prevalence
    p1[1,1] <- pi1*Se1*Se2+(1-pi1)*(1-Sp1)*(1-Sp2)
    p1[1,2] <- pi1*Se1*(1-Se2)+(1-pi1)*(1-Sp1)*Sp2
    p1[2,1] <- pi1*(1-Se1)*Se2+(1-pi1)*Sp1*(1-Sp2)
    p1[2,2] <- pi1*(1-Se1)*(1-Se2)+(1-pi1)*Sp1*Sp2
    
    p2[1,1] <- pi2*Se1*Se2+(1-pi2)*(1-Sp1)*(1-Sp2)
    p2[1,2] <- pi2*Se1*(1-Se2)+(1-pi2)*(1-Sp1)*Sp2
    p2[2,1] <- pi2*(1-Se1)*Se2+(1-pi2)*Sp1*(1-Sp2)
    p2[2,2] <- pi2*(1-Se1)*(1-Se2)+(1-pi2)*Sp1*Sp2

    # Priors
    pi1 ~  dbeta(1,1) #uninformative
    pi2 ~  dbeta(1,1) #uninformative
    Se1 ~ dbeta(138,43)
    Sp1 ~ dbeta(766,5)
    Se2 ~ dbeta(4,6)
    Sp2 ~ dbeta(15,1)
    
}")


#write to temporary text file
write.table(model, file="model.txt", quote=FALSE, sep="", row.names=FALSE, col.names=FALSE)

#Data
#population 1
n1=length(which(btb$Park_ID=="HiP"))
hip=btb[btb$Park_ID=="HiP",]
x1 <- t(matrix(as.vector(table(hip$TBELISA_Result, hip$TST_Result)),2,2))
colnames(x1) <- c("TBELISA-", "TBELISA+")
rownames(x1) <- c("TST-", "TST+")
x1
# this is in the wrong order, and not sure how to get it correct, so just do it manually.
x1<-matrix(c(14,69,86,597),byrow=T,ncol=2, 
           dimnames=list(c("TST+", "TST-"),
                         c("TBELISA+", "TBELISA-")))
x1


#population 2
n2=length(which(btb$Park_ID=="MGR"))

mgr=btb[btb$Park_ID=="MGR",]

x2<- t(matrix(as.vector(table(mgr$TBELISA_Result, mgr$TST_Result)),2,2))
colnames(x2) <- c("TBELISA-", "TBELISA+")
rownames(x2) <- c("TST-", "TST+")
x2

x2<-matrix(c(9,32,39,151),byrow=T,ncol=2, 
           dimnames=list(c("TST+", "TST-"),
                         c("TBELISA+", "TBELISA-")))
x2

#set data inputs to BUGS
dat <- list("x1","n1","x2","n2")

#Set parameters desired to monitor
paras <- c("Se1","Sp1","Se2","Sp2","pi1","pi2")

#Initialising values for 3 chains
inits <- list(
  list(Se1=0.6, Sp1=0.99, Se2=0.2, Sp2=0.92, pi1=0.1, pi2=0.35),
  list(Se1=0.5, Sp1=0.97, Se2=0.1, Sp2=0.90, pi1=0.35, pi2=0.35),
  list(Se1=0.7, Sp1=0.94, Se2=0.3, Sp2=0.94, pi1=0.2, pi2=0.2))

```

```{r Run the model}

# You need Wine to be able to run openBUGS on a mac
#WINE="/usr/local/bin/wine"
#WINEPATH="/usr/local/bin/winepath"
#OpenBUGS.pgm="/Applications/OpenBUGS323/OpenBUGS.exe"

##########################################################
### run model in OpenBUGS ###
niterations=12000
#run with no burnin or thinning, we check these 
# and discard later
bug.out <- bugs(data=dat, inits=inits, parameters.to.save=paras, n.iter=niterations+1, n.burnin=0, n.thin=1, n.chains=3, model.file="model.txt", debug=F, useWINE=T, OpenBUGS.pgm="/Applications/OpenBUGS323/OpenBUGS.exe", WINE="/usr/local/bin/wine", WINEPATH="/usr/local/bin/winepath")
# debug=T will open OpenBUGS window which must be 
# closed to continue
#debug=F will run without opening the OpenBUGS window

##########################################################
### model diagnostics and outputs ###  

# First, check for each inferred parameter that the
# effective sample size (n.eff) is >200 and that the
# potential scale reduction factor (Rhat) is very close 
#to 1. Ignore the posterior density estimates at this 
#stage, because we are yet to discard burn-in. Deviance 
#information criterion (DIC) is also available as an 
#estimate of expected predictive error.
bug.out

# Diagnostics are available when you convert your 
# model output into an MCMC object with this command:
bug.mcmc <- as.mcmc(bug.out)

# html files with trace, density, and autocorrelation,
# all on one page. The files will be displayed in your 
#default internet browser when you open the html file
# produced in the new directory(mcmcout/MCMCoutput.html)
dir.name<-"mcmcout"
if(!dir.exists(dir.name)){dir.create(dir.name)}

mcmcplot(bug.out, title="Diagnostic plots",
         filename = "_MCMCoutput",
         dir = paste0(".//",dir.name,"//"),
         extension = "html")

# Here, we consider convergence to be achieved after
# 2000 iterations, so set the burn-in to 2000
burnin <- 2000

##########################################################
# Final estimates
k<-seq(burnin+1,niterations,1)
# combine chains post-burnin
est<-data.frame(rbind(bug.out$sims.array[k,1,],bug.out$sims.array[k,2,]))
# medians and 95% credible intervals
res<-t(apply(est,2,quantile,probs=c(0.5, 0.025, 0.975)))
round(res, 3)

##########################################################
#plot the marginal posterior distributions versus 
# their priors 
p.a<-c(138,766,4,15,1,1) #se1 a, sp1 a, se2 a, sp2 a, pi1 a, pi2 a
p.b<-c(43,5,6,1,1,1) #se1 b, sp1 b, se2 b, sp2 b, pi1 b, pi2 b
# quartz(); #on Mac; use quartz() or the default plot viewer
par(mfrow=c(3,2))
for (i in 1:6)	{
  plot(density(est[,i], adjust=2), type="l", 
       main=paras[i],
       xlab="Proportion", ylab="Density",
       xlim=c(0,1), lwd=2, las=1,
       cex.main=1.4, cex.lab=1.4, cex.axis=1.4)
  curve(dbeta(x,p.a[i],p.b[i]),lty=2,lwd=2,add=T)
}




```


```{r}

# In both methods the model is super sensitivie to the priors, particularly for the TST. Probably also because we have a lot of data in that prior, more so than for the TBELISA and even more than in the actual dataset. So perhaps it's too informative. Let's see if we can use betabuster instead, or less strong priors.

# We also want to know whether there is a difference in test performance between the parks
# So we should do a multivariate model including location in the model as well as animal-level factors (can we?)

# Might be good also to include a more severe interpretation (compare the different TST interpretations described in the VPN)
# We can only include this for the MGR data and HiP2015 (if we get this data from SUN), as we don't have all the skin test readings for HiP.
# We could also include time point in this regression as we have longitudinal data for MGR.
# Have asked Michele for this data (but may take some time)!

# IDEA: Consider including the LIOdetect in this paper? This one is not conditionally independent from the IDEXX, so then we have to take into account the covDp and covDn like in the Bronsvoort et al. 2019 paper.
```
